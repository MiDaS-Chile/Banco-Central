---
output: 
  html_document:
    theme: paper
---

```{r logo, echo=FALSE, out.width='40%'}
knitr::include_graphics('Logo_midas.PNG')
```

# Solución de Actividades {.tabset}

## Actividad I {.tabset}

### Parte I

Resuelva las siguientes preguntas en `R`:

- Genere un vector con los primeros 1000 números impares.
- Del vector anterior, obtenga los impares número 1, 10, 100 y 1000.
- Cálcule la suma de la raíz de los números generados antes.

#### Solución

```{r}
impares <- seq(1, by = 2, length.out = 1000)
head(impares)
subset <- impares[c(1,10,100,1000)]
subset
sum(sqrt(subset))
```

### Parte II

Instalamos los siguientes paquetes: `babynames`, `nycflights13`, `maps` y los cargamos junto a `tidyverse`.

```{r,message = FALSE,warning = FALSE}

# Paquetes #
library(tidyverse)
library(babynames)
library(nycflights13)
library(maps)

# Datasets #
data("births")
data("nycflights13")
data("maps")
```

Considere la tabla `births` paquete `babynames`. 

(a) ¿Cuántas columnas y filas posee esta tabla?

(b) Utilizando un gráfico adecuado, estudie los nacimientos por años en EE.UU. ¿En qué década se obtuvo la menor cantidad de nacimientos?

#### Solución

(a) Observemos el `glimpse` de la base de datos:

    ```{r}
    glimpse(births)

```

    Luego, hay 109 filas y 2 columnas.


(b) El siguiente código realiza el gráfico:

    ```{r}
ggplot(data = births) +
  geom_line(aes(x = year, y = births),  col = "darkblue") + 
      theme(plot.subtitle = element_text(vjust = 1), 
            plot.caption = element_text(vjust = 1), 
            axis.line = element_line(linetype = "solid"), 
            panel.grid.major = element_line(linetype = "blank"), 
            axis.text = element_text(size = 12), 
            axis.text.x = element_text(size = 12), 
            panel.background = element_rect(fill = NA, linetype = "solid"), 
            legend.key = element_rect(fill = "white"), 
            legend.background = element_rect(fill = NA, linetype = "solid"))
```

    Ahora bien, para obtener la década con menor nacimientos consideramos el siguiente código:
    
    ```{r}
births %>%
      filter(year >= 1910) %>% 
      mutate(decade = floor(year/10)*10) %>% 
      group_by(decade) %>% 
      summarise(nacimientos = sum(births)) %>%
      filter(nacimientos == min(nacimientos))
```
    
    Por lo tanto, la década con menos nacimientos es la década del 30.
    
---

### Parte III

Considere ahora la tabla `babynames` del paquete `babynames`. 

(a) Realice el proceso necesario para obtener la misma estructura en cuanto a **columnas** que la tabla `births`, esto es, generar una nueva tabla que nos entregue el número de nacimientos por año.

(b) Genere un data frame partiendo de la tabla `babynames` que contenga los nacimientos de las personas de género femenino con el nombre **Nala, Ariel** y **Elsa** desde los años 1980.

(c) Con el data frame obtenido en la parte anterior, genere un gráfico que contenga la información de los nacimientos por año de cada uno de los nombres mencionados y mencionte una hipótesis/suposición al respecto de lo observado. *Hint:* Use `face_wrap(~ name, scales = "free_y")`.

#### Solución

(a) El siguiente código realiza lo pedido:

    ```{r}
babynames %>% 
    group_by(year) %>% 
    summarise(births = n() ) -> births2
  head(births2)
```

(b) El siguiente código realiza lo pedido:

    ```{r}
babynames %>%
    filter(sex == "F", year >= 1980, name %in% c("Nala","Ariel","Elsa")) %>% 
    arrange(name) -> births3
  head(births3)
```

(c) El siguiente código resulta en el gráfico pedido

    ```{r}
ggplot(data = births3) + 
   geom_line(aes(x = year, y = n)) +
   facet_wrap( ~ name, ncol = 3, nrow = 1, scales = "free_y")
```


### Parte IV

(a) Utilizando las tablas `airports` y `flights` del paquete `nycflights13` obtenga una tabla que contenga conteos de vuelos según su destino `dest` además de la longitud y latitud del aeropuerto(de destino).

(b) Apoyándose del siguiente gráfico:

    ```{r,message = FALSE, fig.height = 4}
library(maps)
us <- map_data("state")
ggmap <- ggplot() +
  geom_polygon(data = us, aes(long, lat, group = group), alpha = 0.25) +
  coord_fixed() # esto es para mantener la razón 1:1
ggmap
    ```
    
    1. Agregue una capa de puntos ubicando los aeropuertos obtenidos de la pregunta anterior y usando además: `aes(size = la_cantidad_de_vuelos_a_dicho_aeropuerto)`.

    2. A la izquierda del gráfico anterior se observan 2 puntos. Genere el/los pasos necesarios para seleccionarlos usando la tabla resultante de la pregunta 5 para identificar los nombres de dichos aeropuertos y responda: ¿Donde están? ¿Qué gracias tienen?
    
#### Solución

(a) El siguiente código obtiene lo pedido:

    ```{r}
flights %>% 
      left_join(airports, by = c("dest" = "faa")) %>% 
      group_by(name) %>% 
      summarise(nvuelos = n()) %>% 
      left_join(airports, by = "name") %>% 
      select(name,lat,lon,nvuelos) -> airports2
head(airports2)
```

(b) El siguiente código obtiene lo pedido:

    ```{r, warning = FALSE, fig.height = 4}
ggmap <- ggplot() +
    geom_polygon(data = us, aes(long, lat, group = group), alpha = 0.25) + 
    coord_fixed()
ggmap + geom_point(data = airports2, 
               aes(x = lon, y = lat, size = nvuelos, color = "darkblue"), 
               alpha = 0.7)
airports2 %>% 
  filter(lon < -130)
```

## Actividad II {.tabset}

### Parte I

Cree dos funciones para γ(s,x), la primera utilizando la definción y la segunda utilizando su representación en series de potencia. Las funciones no se deben ejecutar si el argumento s es negativo y un mensaje debe ser entregado al usuario.

#### Solución

```{r }
gam1<- function(s,x){
  if(s < 0) stop("s debe ser positivo")
  myf<-function(t){
    t^(s-1)*exp(-t)
  }
  integrate(myf,0,x)$value
}

gam2<- function(s,x){
  if(s < 0) stop("s debe ser positivo")
  k<-0
  aux<-0
  while (!is.infinite(gamma(s+k+1))){
    aux=sum(x^(0:k)/gamma(s+0:k+1))
    k<-k+1
  }
  ifelse(is.infinite(aux),gamma(s),x^s*gamma(s)*exp(-x)*aux)
}
```

### Parte II

Considere el siguiente conjunto de argumentos :$$(s,x)\in {(2,5);(2,20);(10,2);(10,20)}.$$
Evalue las funciones creadas anteriormente y la función `Igamma()` del paquete `zipfR`, y compare los resultados. Además, calcule y compare el tiempo de ejecución.

#### Solución

```{r}
library(zipfR)
library(microbenchmark)
data.frame(Argumentos=c('(2,5)','(2,20)','(10,2)','(10,20)'),
           gam1=c(gam1(2,5),gam1(2,20),gam1(10,2),gam1(10,20)),
           gam2=c(gam2(2,5),gam2(2,20),gam2(10,2),gam2(10,20)),
           Igamma=c(Igamma(2,5),Igamma(2,20),Igamma(10,2),Igamma(10,20)))
```

```{r}
microbenchmark(times = 100, unit = "s", gam1(2,5), gam2(2,5), Igamma(2,3))
microbenchmark(times = 100, unit = "s", gam1(2,20), gam2(2,20), Igamma(2,20))
microbenchmark(times = 100, unit = "s", gam1(10,2), gam2(10,2), Igamma(10,2))
microbenchmark(times = 100, unit = "s", gam1(10,20), gam2(10,20), Igamma(10,20))
```

### Parte III

Utilizando las funciones anteriormente implementadas y la función `Igamma()` encuentre el valor de $s$ que minimiza $\gamma(s,x)$ cuando $x=2$, $x=3$, $x=5$ y $x=100$. Compare los resultados y el tiempo de ejecución.

#### Solución

```{r}
data.frame(x=c(2,3,5,100),
           gam1=c(optimize(gam1,lower=0,upper=4,x=2)$minimum,
                  optimize(gam1,lower=0,upper=4,x=3)$minimum,
                  optimize(gam1,lower=0,upper=4,x=5)$minimum,
                  optimize(gam1,lower=0,upper=4,x=100)$minimum),
           gam2=c(optimize(gam2,lower=0,upper=4,x=2)$minimum,
                  optimize(gam2,lower=0,upper=4,x=3)$minimum,
                  optimize(gam2,lower=0,upper=4,x=5)$minimum,
                  optimize(gam2,lower=0,upper=4,x=100)$minimum),
           Igamma=c(optimize(Igamma,lower=0,upper=4,x=2)$minimum,
                    optimize(Igamma,lower=0,upper=4,x=3)$minimum,
                    optimize(Igamma,lower=0,upper=4,x=5)$minimum,
                    optimize(Igamma,lower=0,upper=4,x=100)$minimum))
```

```{r}
microbenchmark(times = 100, unit = "s", optimize(gam1,lower=0,upper=4,x=2),
               optimize(gam2,lower=0,upper=4,x=2), optimize(Igamma,lower=0,upper=4,x=2))
microbenchmark(times = 100, unit = "s", optimize(gam1,lower=0,upper=4,x=3),
               optimize(gam2,lower=0,upper=4,x=3), optimize(Igamma,lower=0,upper=4,x=3))
microbenchmark(times = 100, unit = "s", optimize(gam1,lower=0,upper=4,x=5),
               optimize(gam2,lower=0,upper=4,x=5), optimize(Igamma,lower=0,upper=4,x=5))
microbenchmark(times = 100, unit = "s", optimize(gam1,lower=0,upper=4,x=100),
               optimize(gam2,lower=0,upper=4,x=100), optimize(Igamma,lower=0,upper=4,x=100))
```

## Actividad III {.tabset}

### Parte I

Considere los datos del siguiente [enlace]("http://midas.mat.uc.cl/courses/bc2019/Datasets/carrera.csv"):

- Si se quiere modelar el tiempo obtenido en la carrera en función de alguna otra variable. ¿Qué variable sugeriría utilizar? Justifique su respuesta indicando las herramientas en las que basó su elección.
- Plantee el modelo adecuado con sus supuestos y ajústelo. Evalúe la significancia de los coeficientes, y en base a ello, escriba la recta estimada.
- Ajuste el modelo de regresión si considerar intercepto. Entregue la recta estimada e interprete el coeficiente en el contexto del problema.

#### Solución

Cargamos los datos:

```{r carrera, message= FALSE}
library(tidyverse)
carrera <- read_delim("http://midas.mat.uc.cl/courses/bc2019/Datasets/carrera.csv", delim = ";")
head(carrera)
```
Queremos modelar el tiempo utilizando alguna de las otras 2 variables. Para escoger entre una de las dos, miremos su correlación lineal:

```{r pairs, fig.height = 4, message = FALSE}
library(GGally)
ggpairs(carrera)
```

En virtud del gráfico de dispersión y del coeficiente de correlación mayor, escogemos la variable altura. El modelo será entonces $$\text{tiempo}_i = \beta_0 + \beta_1\text{altura}_i + \epsilon_i$$ donde $\epsilon_i \overset{iid}{\sim} \text{N}(0,\sigma^2)$. En `R` tenemos:

```{r lm}
modelo1 <- lm(tiempo ~ altura, data = carrera)
summary(modelo1)
```

Notemos que el coeficiente del intercepto es no significativo, por lo cual deberíamos ajustar un modelo que no lo considerara. De todas maneras, la recta estimada será $$\hat{\text{tiempo}}_i = `r round(modelo1$coef[1],2)` + `r round(modelo1$coef[2],2)`\text{altura}_i.$$ El modelo sin intercepto será:  

```{r lm2}
modelo2 <- lm(tiempo ~ altura - 1,data = carrera)
summary(modelo2)
```

El coeficiente asociado a la altura es significativo. De hecho, el modelo ajustado será
$$\hat{\text{tiempo}}_i = `r round(modelo2$coef[1],2)`\text{altura}_i.$$ Gráficamente esto será:

```{r graf lm, fig.height = 4}
library(ggiraph); library(ggiraphExtra)
ggPredict(modelo2,interactive = TRUE)
```

Esto quiere decir que un aumento en una unidad de la altura alcanzada en la carrera significará un aumento de `r round(modelo2$coef[1],2)` minutos en el tiempo de la carrera.

### Parte II

- Grafique los residuos de manera que le permita analizar si está bien especificada la función de la media. Añada las bandas de confianza correspondientes. Identifique qué observaciones son atípicas.
- Obtenga los coeficientes $h_{ii}$ o palanca de cada observación. ¿Qué observación tiene la mayor palanca?
Comente este resultado en conjunto con lo obtenido en la pregunta anterior. 
- Analice la presencia de observaciones influyentes utilizando las Distancias de Cook y los DFFITS.
Comente.

#### Solución

A continuación realizaremos el gráfico de residuos Studentizados versus los valores ajustados del modelo, junto con las respectivas bandas de confianza:

```{r diag1}
data <- tibble("fit" = modelo2$fitted.values, "res" = rstudent(modelo2), labels = seq(1,nrow(carrera)))
ggplot(data, aes(x = fit, y = res, label = labels)) + geom_point() +
  geom_hline(yintercept = qnorm(0.025)) + geom_hline(yintercept = qnorm(0.975)) +
  geom_text(hjust = 1.5, size = 2.5, check_overlap = TRUE) + xlab("Valores ajustados") + 
  ylab("Residuos Studentizados")

```

De aquí vemos que los valores atípicos o outliers son las observaciones 11,31 y 33. Además se observa cierto comportamiento de abertura de megáfono de los datos. Esto nos dice que la función de media no esta bien especificada y que la varianza no cumple el supuesto de homocedasticidad. Para encontrar los $h_{ii}$ junto a las Distancias de Cook y DFFITS utilizamos el siguiente código:

```{r}
summary(influence.measures(modelo2))
```
De aquí, los puntos con mayor palanca son el 7,31,33 y 35. Además según Cooks los puntos influyentes son el 7 y el 33, mientras que según DFFIT estos corresponden a 7,11,31,33 y 35. Para analizar el supuesto de independencia basta utilizar el test de Durbin-Watson:

```{r, message = FALSE}
library(lmtest)
dwtest(tiempo ~ altura - 1, data = carrera)
```

Notar que el valor-$p$ es mayor que 0.05, lo que nos dice que no se rechaza la Hipótesis Nula. Por ende, existe evidencia para decir que los errores son independientes. Finalmente, para el supuesto de normalidad observemos el siguiente qqplot: 

```{r}
ggplot(tibble("res" = modelo2$residuals), aes(sample = res)) + 
  stat_qq() + stat_qq_line()
```

Dado que existen puntos que claramente se escapan de la línea, concluímos que el supuesto de normalidad de los errores no es satisfecho.

## Actividad IV {.tabset}

### Parte I

El archivo `seatbelt.csv` contiene la serie mensual del número de conductores mensualmente muertos o heridos en accidente de tránsito en Gran Bretaña, entre enero de 1969 y diciembre de 1984. Dado lo anterior:

- Importe la BBDD como un `data.frame`.
- Convierta el resultado en una serie de tiempo.
- Estime un modelo de nivel, pendiente y estacionalidad local.
- Grafique los componentes tendencial y estacional ya suavizados.

#### Solución

```{r, message = FALSE}
# Declara las librerías relevantes
library(tidyverse)
library(magrittr)
library(readr)
library(KFAS)

# Importa la BBDD
seatbelt <- readr::read_csv("../Datasets/seatbelt.csv")

# Convierte el resultado en una serie de tiempo
seatbelt <- ts(seatbelt, frequency = 12, start = c(1969, 1))

# Ajusta un modelo estructural (a la Harvey) a estos datos
Q_trend <- list(matrix(NA), matrix(NA))
Q_seas  <- matrix(NA)
fit_01 <- 
  KFAS::SSModel(
    seatbelt ~ -1 + SSMtrend(2, Q_trend) + SSMseasonal(12, Q_seas),
    H = matrix(NA),
    data = seatbelt
  ) %>%
  KFAS::fitSSM(inits = rep(0, 4))

# Aplica el KFS al resultado
kfs_01 <- 
  fit_01 %>%
  magrittr::extract2("model") %>%
  KFAS::KFS() %>%
  magrittr::extract2("alphahat")

# Grafica el componente estacional suavizado
smo <- kfs_01[, 3]
ggplot(tibble(y = smo), aes(x = time(seatbelt))) +
  geom_line(aes(y = y,   colour = "componente estacional (suavizado)"))

# Grafica el componente tendencial suavizado
smo <- kfs_01[, 1]
ggplot(tibble(y = smo), aes(x = time(seatbelt))) +
  geom_line(aes(y = y,   colour = "componente tendencia (suavizado)"))
```

### Parte II

- Reconsidere el ejemplo dado para el filtro de Hamilton.
  - Estime un modelo de nivel, pendiente y estacionalidad local y grafique la tendencia suavizada. ¿Cómo luce en relación a lo obtenido con el filtro de Hamilton?
  - Repita el ejercicio anterior, pero ahora con una pendiente no local sino global.


#### Solución

```{r, message = FALSE}
# Declara las librerías relevantes
library(neverhpfilter)
library(tidyverse)
library(magrittr)
library(KFAS)

# Prepara los datos
y <- ts(log(neverhpfilter::GDPC1), frequency = 4, start = c(1947, 1))

# Calcula la tendencia suavizada (usando un modelo estructural a la Harvey)
smo_trend_01 <- 
  KFAS::SSModel(
    y ~ -1 + SSMtrend(2, Q_trend) + SSMseasonal(4, Q_seas),
    H = matrix(NA),
    data = y
  ) %>%
  KFAS::fitSSM(inits = rep(0, 4)) %>%
  magrittr::extract2("model") %>%
  KFAS::KFS() %>%
  magrittr::extract2("alphahat") %>%
  magrittr::extract(, 1)
  
# Grafica el resultado (junto a la serie original)
ggplot(NULL, aes(x = time(y))) +
  geom_line(aes(y = y,            colour = "serie")) +
  geom_line(aes(y = smo_trend_01, colour = "tendencia (suavizada)"))

# Calcula la tendencia suavizada (pero ahora usado estacionalidad global)
Q_trend <- list(matrix(NA), 0)
Q_seas  <- matrix(NA)
smo_trend_02 <- 
  KFAS::SSModel(
    y ~ -1 + SSMtrend(2, Q_trend) + SSMseasonal(4, Q_seas),
    H = matrix(NA),
    data = y
  ) %>%
  KFAS::fitSSM(inits = rep(0, 3)) %>%
  magrittr::extract2("model") %>%
  KFAS::KFS() %>%
  magrittr::extract2("alphahat") %>%
  magrittr::extract(, 1)

# Grafica el resultado (junto a la serie original)
ggplot(NULL, aes(x = time(y))) +
  geom_line(aes(y = y,            colour = "serie")) +
  geom_line(aes(y = smo_trend_02, colour = "tendencia (suavizada)"))
```

### Parte III

<p align = "justify">
Los archivos `ENE 2018 07 JJA.dta` y `ENE 2019 07 JJA.dta` contienen submuestras de la Encuesta Nacional de Empleo  para los trimestres junio-agosto de 2018 y 2019, respectivamente. </p>
  a. Importe ambas BBDD a R.
  b. Estime el número de ocupados, según trimestre.
  c. Estime la variación porcentual en 12 meses del n. de ocupados.
  d. Estime el número de ocupados por grupo ocupacional, según trimestre.
  e. Estime la variación (%) en 12 meses del n. de ocupados por grupo de ocupación.
  f. Estime la distribución de los ocupados por grupo de ocupación, según trimestre.
  g. Presente los resultados del ítem anterior en un solo cuadro.
  h. Presente los resultados del ítem anterior en un solo gráfico.
  
#### Solución

a. Carga los datos (también cargaremos datos del 2018):
    ```{r}
ene_jja <- list(
  "2018" = haven::read_dta("../Datasets/ENE 2018 07 JJA.dta"),
  "2019" = haven::read_dta("../Datasets/ENE 2019 07 JJA.dta")
)
```

b. Estima el número de ocupados, para los trimestres junio-agosto 2018 y 2019
    ```{r}
ocup_2018 <-
  ene_jja[["2018"]] %>%
  dplyr::filter(activ == 1) %>%
  dplyr::summarise(n = sum(fact)) %>%
  dplyr::pull(1)

ocup_2019 <-
  ene_jja[["2019"]] %>%
  dplyr::filter(activ == 1) %>%
  dplyr::summarise(n = sum(fact)) %>%
  dplyr::pull(1)
```

c. Estima la variación porcentual en 12 meses del número de ocupados
    ```{r}
ocup_vp <- round(100 * (ocup_2019 - ocup_2018) / ocup_2019, 1)
```

d. Estima el número de ocupados, según grupo ocupacional (CIUO 08.cl) para los trimestres junio-agosto 2018 y 2019
    ```{r}
tbl1_2018 <-
  ene_jja[["2018"]] %>%
  dplyr::select(activ, b1, fact) %>%
  dplyr::filter(activ == 1) %>%
  dplyr::group_by(b1) %>%
  dplyr::summarise(n = sum(fact))

tbl1_2019 <-
  ene_jja[["2019"]] %>%
  dplyr::select(activ, b1, fact) %>%
  dplyr::filter(activ == 1) %>%
  dplyr::group_by(b1) %>%
  dplyr::summarise(n = sum(fact))
```

e. Estima el cambio porcentual del número de ocupados, según grupo ocupacional (CIUO 08.cl) entre los trimestres JJA 2018 y JJA 2019
    ```{r}
tbl1 <-
  dplyr::inner_join(tbl1_2018, tbl1_2019, by = "b1") %>%
  dplyr::mutate(delta = 100 * (n.y - n.x) / n.x) %>%
  dplyr::arrange(desc(delta)) %>%
  haven::as_factor()
```

Convierte el resultado en un vector
    ```{r}
pcts <- round(tbl1$delta, 1)
names(pcts) <- tbl1$b1
```

f. Estima la participación de ocupados (en %), según grupo ocupacional (CIUO 08.cl) para los trimestres junio-agosto 2018 y 2019
    ```{r}
tbl2_2019 <-
  ene_jja[["2019"]] %>%
  dplyr::select(activ, b1, fact) %>%
  dplyr::filter(activ == 1) %>%
  dplyr::group_by(b1) %>%
  dplyr::summarise(n = sum(fact)) %>%
  dplyr::mutate(
    pct       = 100 * n / sum(n),
    trimestre = "junio-agosto 2019"
  )

tbl2_2018 <-
  ene_jja[["2018"]] %>%
  dplyr::select(activ, b1, fact) %>%
  dplyr::filter(activ == 1) %>%
  dplyr::group_by(b1) %>%
  dplyr::summarise(n = sum(fact)) %>%
  dplyr::mutate(
    pct       = 100 * n / sum(n),
    trimestre = "junio-agosto 2018"
  )
```

g. Combina la información en una tabla
    ```{r}
tbl2_3FN <-
  rbind(tbl2_2018, tbl2_2019) %>%
  dplyr::select(b1, pct, trimestre) %>%
  dplyr::mutate(
    trimestre = haven::as_factor(trimestre),
    b1        = haven::as_factor(b1)
  )
```

h. Combina la información en un gráfico
    ```{r}
tbl2_3FN %>%
  ggplot2::ggplot(aes(stringr::str_wrap(b1, 25), pct, fill = trimestre)) +
  ggplot2::geom_bar(position = "dodge", stat = "identity") +
  ggplot2::coord_flip() +
  ggplot2::scale_fill_manual(values = c("darkblue", "darkred")) +
  ggplot2::labs(
    x        = "Grupo ocupacional (CIUO 08.cl)",
    y        = "Participación (%)",
    title    = "Gráfico 1. Participación de ocupados",
    subtitle = "según grupo ocupacional (CIUO 08.cl)",
    caption  = "Elaboración propia en base a datos de la ENE 2018/2019."
  )
```
